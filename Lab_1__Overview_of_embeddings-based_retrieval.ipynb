{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Overview of embeddings-based retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we can find first a sample of how a document can be prepared and added into Chroma DB.    \n",
    "Then we create a RAG methon and use a LLM (ChatGPT) to answer a question based on the output of queryng the DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"The-Mom-Test-en.pdf\")\n",
    "\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pdf_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 232\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damiangarayalde/Desktop/Work - Github Repos/AI/Advanced Retrieval for AI with Chroma/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failing the mom test son : “ mom, mom, i have an idea for a business — can i run it by you? ” i am about to expose my ego — please don ’ t hurt my feelings. mom : “ of course, dear. ” you are my only son and i am ready to lie to protect you. son : “ you like your ipad, right? you use it a lot? ” mom : “ yes. ” you led me to this answer, so here you go. son : “ okay, so would you ever buy an app which was like a cookbook for your ipad? ” i am optimistically asking a hypothetical question and you know what i want you to say. mom : “ hmmm. ” as if i need another cookbook at my age. son : “ and it only costs $ 40 — that ’ s cheaper than those hardcovers on your shelf. ” i ’ m going to skip that lukewarm signal and tell you more about my great idea. mom : “ well... ” aren ’ t apps supposed to cost a dollar? son : “ and you can share recipes with your friends, and there ’ s an iphone app which is your shopping list. and videos of that celebrity chef you love.\n",
      "\n",
      "Total chunks: 236\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "   \n",
    "print(token_split_texts[10])\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.054110657423734665, 0.10771001875400543, -0.005316439084708691, -0.03969819098711014, 0.025499017909169197, -0.018412992358207703, 0.005782117135822773, 0.05646170675754547, 0.09644944220781326, 0.016840169206261635, 0.05963132530450821, -0.025572126731276512, -0.021317411214113235, -0.04658119007945061, 0.08316187560558319, -0.0281317550688982, 0.12755519151687622, -0.017795145511627197, -0.07733485102653503, 0.002549288794398308, -0.02086193673312664, 0.03136380389332771, 0.11139810085296631, 0.03590168431401253, 0.03599106892943382, 0.04973244667053223, -0.0028566515538841486, -0.05273302271962166, -0.09187264740467072, 0.04816967621445656, 0.018823346123099327, -0.03593284636735916, -0.01929320953786373, 0.044532742351293564, 0.0014540485572069883, -0.07881123572587967, -0.006094179581850767, 0.016404516994953156, -0.02853977121412754, -0.07467714697122574, -0.01987944357097149, 0.037578143179416656, -0.0681605190038681, 0.033071838319301605, 0.01004654448479414, -0.026650704443454742, 0.027928953990340233, -0.0019583706744015217, 0.00689570652320981, 0.026353027671575546, -0.048260267823934555, -0.04870303347706795, -0.048484545201063156, -0.04847099632024765, -0.006906623020768166, 0.030799265950918198, 0.01606186293065548, -0.0084471944719553, 0.06692080199718475, 0.10576064884662628, -0.03256075084209442, -0.01358446292579174, 0.02167774923145771, 0.05596396327018738, 0.030464468523859978, -0.011175260879099369, -0.01792917400598526, -0.006292468402534723, -0.0852566659450531, 0.04340796917676926, -0.005266193300485611, 0.07386469095945358, 0.04078645631670952, 0.04781058430671692, 0.003978526685386896, -0.013103412464261055, 0.029716849327087402, -0.046855028718709946, -0.025802619755268097, -0.008340615779161453, -0.06290827691555023, 0.03875145688652992, -0.04546703025698662, 0.00974752102047205, -0.03440098091959953, -0.019982583820819855, 0.07159608602523804, -0.024314969778060913, 0.04677530378103256, 0.010231942869722843, -0.011042305268347263, -0.020374909043312073, 0.0593533031642437, 0.001621124567463994, 0.047050390392541885, -0.0006008619675412774, -0.02644817903637886, -0.045405756682157516, -0.11343973875045776, -0.06487280875444412, 0.010800664313137531, 0.038313962519168854, 0.05425317585468292, -0.02800251543521881, 0.038718484342098236, -0.03692971542477608, -0.004701115190982819, -0.05376084893941879, 0.027875473722815514, 0.06890642642974854, -0.021583711728453636, -0.055499471724033356, -0.01945827342569828, -0.03143046051263809, 0.02795511856675148, -0.047974374145269394, 0.04949761554598808, 0.06269461661577225, 0.027555212378501892, 0.003746005706489086, -0.027226192876696587, 0.08135610818862915, 0.061858825385570526, 0.011086509563028812, -0.08304832875728607, -0.13533949851989746, -0.04242778196930885, -2.8602742005322235e-33, -0.01111005898565054, 0.09446903318166733, -0.01754930056631565, 0.07319068908691406, 0.020359687507152557, 0.013170951046049595, 0.05372656509280205, 0.10039205849170685, -0.03305485472083092, 0.062095511704683304, -0.004665306303650141, 0.011208999902009964, -0.006706266663968563, 0.03386326879262924, 0.05781387910246849, 0.08899129182100296, -0.0854731872677803, -0.008063486777245998, 0.10296536237001419, -0.040275685489177704, -0.05965126305818558, -0.06539180129766464, -0.02512381412088871, -0.08172757178544998, 0.0015493115643039346, -0.07718538492918015, 0.06874433159828186, -0.00016609844169579446, 0.022814638912677765, -0.045183293521404266, -0.12478479743003845, -0.022193236276507378, -0.021739237010478973, -0.11319182068109512, -0.027951324358582497, -0.024763580411672592, 0.032869793474674225, -0.052421316504478455, 0.03049125149846077, 0.024051284417510033, -0.17234690487384796, -0.043662942945957184, 0.014699524268507957, 0.024723760783672333, 0.009317577816545963, 0.002335072960704565, 0.028221506625413895, 0.020139295607805252, -0.032823748886585236, -0.030742524191737175, -0.06345837563276291, -0.03735138848423958, 0.025217728689312935, -0.02901359088718891, -0.10841529816389084, -0.024301432073116302, 0.03948894515633583, -0.060474641621112823, 0.046400975435972214, -0.032597873359918594, 0.05756249651312828, -0.07029996812343597, -0.042122721672058105, 0.07914944738149643, -0.135682612657547, 0.029682256281375885, 0.014746015891432762, 0.019571999087929726, -0.0017358546610921621, -0.003318577306345105, -0.03180404007434845, -0.08900396525859833, -0.056368373334407806, -0.09119134396314621, 0.01731967367231846, 0.05409422144293785, 0.003118810709565878, 0.06249052286148071, 0.013851353898644447, -0.10129004716873169, 0.08780758827924728, -0.052723340690135956, 0.017918752506375313, 0.051600292325019836, -0.07960627228021622, 0.04445677623152733, -0.04136115685105324, -0.059872955083847046, -0.04682452231645584, 0.06322533637285233, -0.07406241446733475, 0.015079201199114323, 0.015061586163938046, 0.01740863546729088, 0.04373657703399658, -3.7020706844110186e-34, -0.0138445058837533, 0.005119390320032835, 0.005874458234757185, 0.012700216844677925, 0.06851805746555328, -0.1193540096282959, 0.0007689944468438625, -0.00708616292104125, 0.016507402062416077, -0.06214709207415581, -0.1140417531132698, 0.016967125236988068, -0.007463184185326099, -0.04095400869846344, -0.030078012496232986, -0.010059090331196785, -0.03358224779367447, -0.03686381131410599, 0.028759274631738663, -0.06615401059389114, -0.06210339441895485, 0.06897737830877304, 0.014469648711383343, 0.018369002267718315, -0.031247368082404137, -0.05169139429926872, -0.022879498079419136, -0.004224273841828108, -0.026586001738905907, -0.02753758803009987, 0.0513322576880455, -0.09130986034870148, 0.050230614840984344, 0.06287836283445358, -0.030905354768037796, 0.05304386094212532, -0.02734276093542576, -0.050593096762895584, -0.04794837906956673, 0.012430194765329361, 0.10109046846628189, -0.02528916671872139, -0.010321958921849728, 0.04264223948121071, -0.009798974730074406, -0.0232648104429245, 0.05137323960661888, -0.02770845778286457, 0.03778216987848282, 0.06596630811691284, -0.0012364404974505305, 0.0055723791010677814, -0.0025517642498016357, 0.00521635077893734, -0.034886449575424194, 0.0927126556634903, 0.06277317553758621, -0.00027884813607670367, 0.07431887835264206, -0.01119780819863081, 0.06902223825454712, 0.05819673091173172, 0.009604906663298607, -0.015646135434508324, -0.08894999325275421, -0.041809018701314926, 0.057230107486248016, 0.005360262468457222, 0.009482043795287609, 0.08254148811101913, -0.007257492747157812, 0.020625656470656395, -0.000907042296603322, -0.06179477646946907, -0.059485021978616714, 0.10285945236682892, 0.08234021812677383, -0.050974223762750626, -0.029623836278915405, -0.03040941245853901, 0.036228809505701065, 0.008073568344116211, 0.05858074501156807, -0.04493732005357742, 0.023658130317926407, -0.06637357920408249, -0.025403788313269615, -0.063383549451828, -0.04563789814710617, 0.0895698145031929, 0.018515078350901604, 0.020253023132681847, -0.01005116943269968, 0.05531400814652443, -0.013265150599181652, -5.291865079470881e-08, 0.07384826987981796, -0.03147842735052109, 0.06631619483232498, 0.031628187745809555, 0.0010306575568392873, -0.05629660561680794, 0.03798724710941315, -0.0314004085958004, 0.03758074715733528, -0.012089068070054054, -0.010532861575484276, -0.06426732242107391, -0.12303059548139572, 0.054353468120098114, 0.020523184910416603, 0.023042665794491768, 0.11089184880256653, -0.05043600872159004, 0.016729576513171196, 0.029019474983215332, 0.04886350780725479, 0.10242360830307007, -0.005139994900673628, 0.04228057339787483, -0.046271007508039474, 0.007940617389976978, 0.02622145041823387, 0.06367643177509308, -0.009524100460112095, 0.10670724511146545, 0.026114393025636673, -0.017636260017752647, -0.0019379364093765616, -0.0025943913497030735, -0.02207925356924534, -0.08784313499927521, -0.0534585565328598, 0.036706700921058655, 0.03777183219790459, 0.01232215203344822, -0.05003172531723976, -0.032656557857990265, 0.009520275518298149, 0.0073354835622012615, 0.005015915725380182, 0.002198694972321391, -0.07293074578046799, -0.07000365853309631, 0.006857046391814947, 0.14863373339176178, -0.02713621035218239, -0.034703679382801056, 0.03768206760287285, -0.03726674243807793, 0.02846800908446312, -0.019354837015271187, 0.0034583252854645252, 0.014697364531457424, -0.05475049838423729, 0.0473598875105381, 0.12166746705770493, -0.08740920573472977, 0.007400596048682928, 0.003972395323216915]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# The string is just the collection name. \n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\"TheMomTest_book\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "# The .add method will embedd the token_split_texts using the embedding_function specified above\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spindler, and tim barnes for showing me the good bits of the startup education world and giving me my first chance to teach. beyond the obvious influence from steve blank and eric ries, a big thanks to some other writers who have directly helped this book with their work : amy hoy on worldviews, brant cooper on segmentation, richard rumelt and lafley / martin on strategy, neil rackham on sales, and derek sivers on remembering that businesses are meant to make you happy. and of course, big thanks for mom & dad for gently planting the entrepreneurial seed through both encouragement and their own collection of insane startup and / or shipwreck stories. the cover was put together by devin hunt. the author image is provided by heisenbergmedia. com. thanks! 121\n",
      "\n",
      "\n",
      "this book isn ’ t a summary or description or re - interpretation of the process of customer development. that ’ s a bigger concept and something steve blank has covered comprehensively in 4 steps to the e. piphany and the startup owner ’ s manual. this book is specifically about how to properly talk to customers and learn from them. talking is one of the big aspects of customer development, but shouldn't be confused with the whole process. to keep the distinction clear, i ’ m going to refer to chatting with people as “ customer conversation ” ( lowercase ) instead of “ customer development ” ( uppercase ). for the most part, i'm assuming you already agree that talking to customers is a good idea. i ’ m not trying to convince you again, so this book is more “ how ” than “ why ”. let ’ s get involved. 7\n",
      "\n",
      "\n",
      "totally ideal customers who are already spending time and money to try to get better. on the other hand, if you were attacking the same vision and happened to be a secret bibliophile, you might choose to start by tracking down some authors who are about to go on book tour. you needn ’ t be planning and theorising all day about this stuff — use it to quickly get to a specific, best - possible customer so you can go grab a few of 96\n",
      "\n",
      "\n",
      "is this book for you? hello, you ’ ve read about customer development or lean startup and aren ’ t sure how to actually go about having your first customer conversation. you ’ re a traditional business or sales person aiming to be more effective within a young company which hasn ’ t yet found its business model. you mentor, support, or invest in startups and want to help them have more useful customer conversations. you ’ ve fallen in love with a new business idea and want to figure out if it has legs before quitting your job. you ’ re raising funding and the investors want to see more evidence that you ’ re solving a real problem. you find this whole process incredibly awkward and really wish there was an easier way to do it. you ’ ve got a vague sense of an opportunity and want to figure out exactly what it is. you ’ ve always wanted to build your own company and want to start making real progress today. this book is for you. 4\n",
      "\n",
      "\n",
      "to solve the petty annoyances of their day.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the main idea behind the book?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "\n",
    "# Under the hood the .query() method will embedd the query using the same embedding funtion used when adding the documents. \n",
    "# Here is where chroma_db searchs for the documents that look similar to the query and then return some documents (5 here)\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a seasoned educator counseling fresh entrepreneurs in YCombinator. Your users are asking questions about information contained in the book.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the book. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main idea behind the book is to provide guidance on how to properly talk to customers and learn from them. It is not a summary or description of the process of customer development, but rather focuses specifically on customer conversation. The book is intended for individuals who have read about customer development or lean startup and want to know how to have their first customer conversation, traditional business or sales people looking to be more effective in a young company, mentors, supporters, or investors in startups who want to help them have more useful customer conversations, individuals who have a new business idea and want to determine its viability before quitting their job, those seeking funding who need more evidence of solving a real problem, individuals who find the process of customer conversation awkward and want an easier way to do it, those with a vague sense of an opportunity and want to clarify it, and individuals who have always wanted to start their own company and want to make real progress.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
