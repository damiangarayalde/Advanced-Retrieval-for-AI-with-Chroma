{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Overview of embeddings-based retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we can find first a sample of how a document can be prepared and added into Chroma DB.    \n",
    "Then we create a RAG methon and use a LLM (ChatGPT) to answer a question based on the output of queryng the DB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"microsoft_annual_report_2022.pdf\")\n",
    "\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "# Filter the empty strings\n",
    "pdf_texts = [text for text in pdf_texts if text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pdf_texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total chunks: 347\n"
     ]
    }
   ],
   "source": [
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "print(f\"\\nTotal chunks: {len(character_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damiangarayalde/Desktop/Work - Github Repos/AI/Advanced Retrieval for AI with Chroma/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increased, due in large part to significant global datacenter expansions and the growth in xbox sales and usage. despite these increases, we remain dedicated to achieving a net - zero future. we recognize that progress won â€™ t always be linear, and the rate at which we can implement emissions reductions is dependent on many factors that can fluctuate over time. on the path to becoming water positive, we invested in 21 water replenishment projects that are expected to generate over 1. 3 million cubic meters of volumetric benefits in nine water basins around the world. progress toward our zero waste commitment included diverting more than 15, 200 metric tons of solid waste otherwise headed to landfills and incinerators, as well as launching new circular centers to increase reuse and reduce e - waste at our datacenters. we contracted to protect over 17, 000 acres of land ( 50 % more than the land we use to operate ), thus achieving our\n",
      "\n",
      "Total chunks: 349\n"
     ]
    }
   ],
   "source": [
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "   \n",
    "print(token_split_texts[10])\n",
    "print(f\"\\nTotal chunks: {len(token_split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.054110657423734665, 0.10771001875400543, -0.005316439084708691, -0.03969819098711014, 0.025499017909169197, -0.018412992358207703, 0.005782117135822773, 0.05646170675754547, 0.09644944220781326, 0.016840169206261635, 0.05963132530450821, -0.025572126731276512, -0.021317411214113235, -0.04658119007945061, 0.08316187560558319, -0.0281317550688982, 0.12755519151687622, -0.017795145511627197, -0.07733485102653503, 0.002549288794398308, -0.02086193673312664, 0.03136380389332771, 0.11139810085296631, 0.03590168431401253, 0.03599106892943382, 0.04973244667053223, -0.0028566515538841486, -0.05273302271962166, -0.09187264740467072, 0.04816967621445656, 0.018823346123099327, -0.03593284636735916, -0.01929320953786373, 0.044532742351293564, 0.0014540485572069883, -0.07881123572587967, -0.006094179581850767, 0.016404516994953156, -0.02853977121412754, -0.07467714697122574, -0.01987944357097149, 0.037578143179416656, -0.0681605190038681, 0.033071838319301605, 0.01004654448479414, -0.026650704443454742, 0.027928953990340233, -0.0019583706744015217, 0.00689570652320981, 0.026353027671575546, -0.048260267823934555, -0.04870303347706795, -0.048484545201063156, -0.04847099632024765, -0.006906623020768166, 0.030799265950918198, 0.01606186293065548, -0.0084471944719553, 0.06692080199718475, 0.10576064884662628, -0.03256075084209442, -0.01358446292579174, 0.02167774923145771, 0.05596396327018738, 0.030464468523859978, -0.011175260879099369, -0.01792917400598526, -0.006292468402534723, -0.0852566659450531, 0.04340796917676926, -0.005266193300485611, 0.07386469095945358, 0.04078645631670952, 0.04781058430671692, 0.003978526685386896, -0.013103412464261055, 0.029716849327087402, -0.046855028718709946, -0.025802619755268097, -0.008340615779161453, -0.06290827691555023, 0.03875145688652992, -0.04546703025698662, 0.00974752102047205, -0.03440098091959953, -0.019982583820819855, 0.07159608602523804, -0.024314969778060913, 0.04677530378103256, 0.010231942869722843, -0.011042305268347263, -0.020374909043312073, 0.0593533031642437, 0.001621124567463994, 0.047050390392541885, -0.0006008619675412774, -0.02644817903637886, -0.045405756682157516, -0.11343973875045776, -0.06487280875444412, 0.010800664313137531, 0.038313962519168854, 0.05425317585468292, -0.02800251543521881, 0.038718484342098236, -0.03692971542477608, -0.004701115190982819, -0.05376084893941879, 0.027875473722815514, 0.06890642642974854, -0.021583711728453636, -0.055499471724033356, -0.01945827342569828, -0.03143046051263809, 0.02795511856675148, -0.047974374145269394, 0.04949761554598808, 0.06269461661577225, 0.027555212378501892, 0.003746005706489086, -0.027226192876696587, 0.08135610818862915, 0.061858825385570526, 0.011086509563028812, -0.08304832875728607, -0.13533949851989746, -0.04242778196930885, -2.8602742005322235e-33, -0.01111005898565054, 0.09446903318166733, -0.01754930056631565, 0.07319068908691406, 0.020359687507152557, 0.013170951046049595, 0.05372656509280205, 0.10039205849170685, -0.03305485472083092, 0.062095511704683304, -0.004665306303650141, 0.011208999902009964, -0.006706266663968563, 0.03386326879262924, 0.05781387910246849, 0.08899129182100296, -0.0854731872677803, -0.008063486777245998, 0.10296536237001419, -0.040275685489177704, -0.05965126305818558, -0.06539180129766464, -0.02512381412088871, -0.08172757178544998, 0.0015493115643039346, -0.07718538492918015, 0.06874433159828186, -0.00016609844169579446, 0.022814638912677765, -0.045183293521404266, -0.12478479743003845, -0.022193236276507378, -0.021739237010478973, -0.11319182068109512, -0.027951324358582497, -0.024763580411672592, 0.032869793474674225, -0.052421316504478455, 0.03049125149846077, 0.024051284417510033, -0.17234690487384796, -0.043662942945957184, 0.014699524268507957, 0.024723760783672333, 0.009317577816545963, 0.002335072960704565, 0.028221506625413895, 0.020139295607805252, -0.032823748886585236, -0.030742524191737175, -0.06345837563276291, -0.03735138848423958, 0.025217728689312935, -0.02901359088718891, -0.10841529816389084, -0.024301432073116302, 0.03948894515633583, -0.060474641621112823, 0.046400975435972214, -0.032597873359918594, 0.05756249651312828, -0.07029996812343597, -0.042122721672058105, 0.07914944738149643, -0.135682612657547, 0.029682256281375885, 0.014746015891432762, 0.019571999087929726, -0.0017358546610921621, -0.003318577306345105, -0.03180404007434845, -0.08900396525859833, -0.056368373334407806, -0.09119134396314621, 0.01731967367231846, 0.05409422144293785, 0.003118810709565878, 0.06249052286148071, 0.013851353898644447, -0.10129004716873169, 0.08780758827924728, -0.052723340690135956, 0.017918752506375313, 0.051600292325019836, -0.07960627228021622, 0.04445677623152733, -0.04136115685105324, -0.059872955083847046, -0.04682452231645584, 0.06322533637285233, -0.07406241446733475, 0.015079201199114323, 0.015061586163938046, 0.01740863546729088, 0.04373657703399658, -3.7020706844110186e-34, -0.0138445058837533, 0.005119390320032835, 0.005874458234757185, 0.012700216844677925, 0.06851805746555328, -0.1193540096282959, 0.0007689944468438625, -0.00708616292104125, 0.016507402062416077, -0.06214709207415581, -0.1140417531132698, 0.016967125236988068, -0.007463184185326099, -0.04095400869846344, -0.030078012496232986, -0.010059090331196785, -0.03358224779367447, -0.03686381131410599, 0.028759274631738663, -0.06615401059389114, -0.06210339441895485, 0.06897737830877304, 0.014469648711383343, 0.018369002267718315, -0.031247368082404137, -0.05169139429926872, -0.022879498079419136, -0.004224273841828108, -0.026586001738905907, -0.02753758803009987, 0.0513322576880455, -0.09130986034870148, 0.050230614840984344, 0.06287836283445358, -0.030905354768037796, 0.05304386094212532, -0.02734276093542576, -0.050593096762895584, -0.04794837906956673, 0.012430194765329361, 0.10109046846628189, -0.02528916671872139, -0.010321958921849728, 0.04264223948121071, -0.009798974730074406, -0.0232648104429245, 0.05137323960661888, -0.02770845778286457, 0.03778216987848282, 0.06596630811691284, -0.0012364404974505305, 0.0055723791010677814, -0.0025517642498016357, 0.00521635077893734, -0.034886449575424194, 0.0927126556634903, 0.06277317553758621, -0.00027884813607670367, 0.07431887835264206, -0.01119780819863081, 0.06902223825454712, 0.05819673091173172, 0.009604906663298607, -0.015646135434508324, -0.08894999325275421, -0.041809018701314926, 0.057230107486248016, 0.005360262468457222, 0.009482043795287609, 0.08254148811101913, -0.007257492747157812, 0.020625656470656395, -0.000907042296603322, -0.06179477646946907, -0.059485021978616714, 0.10285945236682892, 0.08234021812677383, -0.050974223762750626, -0.029623836278915405, -0.03040941245853901, 0.036228809505701065, 0.008073568344116211, 0.05858074501156807, -0.04493732005357742, 0.023658130317926407, -0.06637357920408249, -0.025403788313269615, -0.063383549451828, -0.04563789814710617, 0.0895698145031929, 0.018515078350901604, 0.020253023132681847, -0.01005116943269968, 0.05531400814652443, -0.013265150599181652, -5.291865079470881e-08, 0.07384826987981796, -0.03147842735052109, 0.06631619483232498, 0.031628187745809555, 0.0010306575568392873, -0.05629660561680794, 0.03798724710941315, -0.0314004085958004, 0.03758074715733528, -0.012089068070054054, -0.010532861575484276, -0.06426732242107391, -0.12303059548139572, 0.054353468120098114, 0.020523184910416603, 0.023042665794491768, 0.11089184880256653, -0.05043600872159004, 0.016729576513171196, 0.029019474983215332, 0.04886350780725479, 0.10242360830307007, -0.005139994900673628, 0.04228057339787483, -0.046271007508039474, 0.007940617389976978, 0.02622145041823387, 0.06367643177509308, -0.009524100460112095, 0.10670724511146545, 0.026114393025636673, -0.017636260017752647, -0.0019379364093765616, -0.0025943913497030735, -0.02207925356924534, -0.08784313499927521, -0.0534585565328598, 0.036706700921058655, 0.03777183219790459, 0.01232215203344822, -0.05003172531723976, -0.032656557857990265, 0.009520275518298149, 0.0073354835622012615, 0.005015915725380182, 0.002198694972321391, -0.07293074578046799, -0.07000365853309631, 0.006857046391814947, 0.14863373339176178, -0.02713621035218239, -0.034703679382801056, 0.03768206760287285, -0.03726674243807793, 0.02846800908446312, -0.019354837015271187, 0.0034583252854645252, 0.014697364531457424, -0.05475049838423729, 0.0473598875105381, 0.12166746705770493, -0.08740920573472977, 0.007400596048682928, 0.003972395323216915]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "#print(embedding_function([token_split_texts[10]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "349"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "\n",
    "# The string is just the collection name. \n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\"MicrosoftAnnualReport\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "# The .add method will embedd the token_split_texts using the embedding_function specified above\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue, classified by significant product and service offerings, was as follows : ( in millions ) year ended june 30, 2022 2021 2020 server products and cloud services $ 67, 321 $ 52, 589 $ 41, 379 office products and cloud services 44, 862 39, 872 35, 316 windows 24, 761 22, 488 21, 510 gaming 16, 230 15, 370 11, 575 linkedin 13, 816 10, 289 8, 077 search and news advertising 11, 591 9, 267 8, 524 enterprise services 7, 407 6, 943 6, 409 devices 6, 991 6, 791 6, 457 other 5, 291 4, 479 3, 768 total $ 198, 270 $ 168, 088 $ 143, 015 we have recast certain previously reported amounts in the table above to conform to the way we internally manage and monitor our business.\n",
      "\n",
      "\n",
      "74 note 13 â€” unearned revenue unearned revenue by segment was as follows : ( in millions ) june 30, 2022 2021 productivity and business processes $ 24, 558 $ 22, 120 intelligent cloud 19, 371 17, 710 more personal computing 4, 479 4, 311 total $ 48, 408 $ 44, 141 changes in unearned revenue were as follows : ( in millions ) year ended june 30, 2022 balance, beginning of period $ 44, 141 deferral of revenue 110, 455 recognition of unearned revenue ( 106, 188 ) balance, end of period $ 48, 408 revenue allocated to remaining performance obligations, which includes unearned revenue and amounts that will be invoiced and recognized as revenue in future periods, was $ 193 billion as of june 30, 2022, of which $ 189 billion is related to the commercial portion of revenue. we expect to recognize approximately 45 % of this revenue over the next 12\n",
      "\n",
      "\n",
      "that are not sold separately. â€¢ we tested the mathematical accuracy of management â€™ s calculations of revenue and the associated timing of revenue recognized in the financial statements.\n",
      "\n",
      "\n",
      "82 in addition, certain costs incurred at a corporate level that are identifiable and that benefit our segments are allocated to them. these allocated costs include legal, including settlements and fines, information technology, human resources, finance, excise taxes, field selling, shared facilities services, and customer service and support. each allocation is measured differently based on the specific facts and circumstances of the costs being allocated. segment revenue and operating income were as follows during the periods presented : ( in millions ) year ended june 30, 2022 2021 2020 revenue productivity and business processes $ 63, 364 $ 53, 915 $ 46, 398 intelligent cloud 75, 251 60, 080 48, 366 more personal computing 59, 655 54, 093 48, 251 total $ 198, 270 $ 168, 088 $ 143, 015 operating income\n",
      "\n",
      "\n",
      "47 financial statements and supplementary data income statements ( in millions, except per share amounts ) year ended june 30, 2022 2021 2020 revenue : product $ 72, 732 $ 71, 074 $ 68, 041 service and other 125, 538 97, 014 74, 974 total revenue 198, 270 168, 088 143, 015 cost of revenue : product 19, 064 18, 219 16, 017 service and other 43, 586 34, 013 30, 061 total cost of revenue 62, 650 52, 232 46, 078 gross margin 135, 620 115, 856 96, 937 research and development 24, 512 20, 716 19, 269 sales and marketing 21, 825 20, 117 19, 598 general and administrative 5, 900 5, 107 5, 111 operating income 83, 383 69, 916 52, 959 other income, net 333 1, 186 77 income before income taxes 83, 716 71, 102 53, 036 provision for income taxes 10, 978 9, 831 8, 755\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the total revenue?\"\n",
    "\n",
    "results = chroma_collection.query(query_texts=[query], n_results=5)\n",
    "\n",
    "# Under the hood the .query() method will embedd the query using the same embedding funtion used when adding the documents. \n",
    "# Here is where chroma_db searchs for the documents that look similar to the query and then return some documents (5 here)\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in retrieved_documents:\n",
    "    print(document)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "openai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query, retrieved_documents, model=\"gpt-3.5-turbo\"):\n",
    "    information = \"\\n\\n\".join(retrieved_documents)\n",
    "\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful expert financial research assistant. Your users are asking questions about information contained in an annual report.\"\n",
    "            \"You will be shown the user's question, and the relevant information from the annual report. Answer the user's question using only this information.\"\n",
    "        },\n",
    "        {\"role\": \"user\", \"content\": f\"Question: {query}. \\n Information: {information}\"}\n",
    "    ]\n",
    "    \n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "    )\n",
    "    content = response.choices[0].message.content\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total revenue for the year ended June 30, 2022, was $198,270 million.\n"
     ]
    }
   ],
   "source": [
    "output = rag(query=query, retrieved_documents=retrieved_documents)\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
