{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 4 - Cross-encoder re-ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/damiangarayalde/Desktop/Work - Github Repos/AI/Advanced Retrieval for AI with Chroma/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell is the same as Lab 1 till we create the collection collapsed into a single block\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, SentenceTransformersTokenTextSplitter\n",
    "\n",
    "reader = PdfReader(\"The-Mom-Test-en.pdf\")\n",
    "\n",
    "pdf_texts = [p.extract_text().strip() for p in reader.pages]\n",
    "\n",
    "pdf_texts = [text for text in pdf_texts if text]  # Filter the empty strings\n",
    "\n",
    "character_splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "character_split_texts = character_splitter.split_text('\\n\\n'.join(pdf_texts))\n",
    "\n",
    "token_splitter = SentenceTransformersTokenTextSplitter(chunk_overlap=0, tokens_per_chunk=256)\n",
    "\n",
    "token_split_texts = []\n",
    "for text in character_split_texts:\n",
    "    token_split_texts += token_splitter.split_text(text)\n",
    "   \n",
    "\n",
    "embedding_function = SentenceTransformerEmbeddingFunction()\n",
    "\n",
    "chroma_client = chromadb.Client()\n",
    "\n",
    "chroma_collection = chroma_client.create_collection(\"TheMomTest_book\", embedding_function=embedding_function)\n",
    "\n",
    "ids = [str(i) for i in range(len(token_split_texts))]\n",
    "\n",
    "chroma_collection.add(ids=ids, documents=token_split_texts)\n",
    "\n",
    "chroma_collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-ranking the long tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to make matters worse, the feedback they ’ re getting is absurdly inconsistent. if they run twenty conversations, they end up with twenty different must - have features and twenty separate must - solve problems. the more people they talk to, the more confused they get. what ’ s going on here? their customer segment was incredibly broad, but in a sneaky way. imagine i tell you my customer segment is “ students ”. okay, you say, with a picture of an american undergraduate university student in your head. maybe it ’ s a male student. he sits down in the lecture hall, cracks open his mac ( adding to the sea of glowing apples the professor ’ s view has recently become ), and fires up reddit to help him survive the next ninety minutes. so i ’ ve built a product for students, and feedback starts coming in. but it ’ s not what i expect. one user needs to add formal citations. another wants practice questions. a third needs it to run on the ipad. a fourth needs eighty\n",
      "\n",
      "did you notice that in the conversations above, practically every response contains a sneaky compliment? they are pervasive, constantly trying to trick us into thinking the conversation “ went well ”. ignoring compliments should be easy, but it ’ s not. we so desperately want to hear them that we are often tricked into registering them as positive data points instead of vacuous fibs. sometimes it ’ s easier to spot the symptoms than to notice the original compliment. symptoms ( in the meeting ) : “ thanks! ” “ i ’ m glad you like it. ” symptoms ( back at the office ) : “ that meeting went really well. ” “ we ’ re getting a lot of positive feedback. ” “ everybody i ’ ve talked to loves the idea. ” all of these are warning signs. if you catch yourself or your teammates saying something like this, try to get specific. why did that person like the idea? how much money would it save him? how would it fit into his life? what else has he tried which failed to solve his problem? if you don ’ t know,\n",
      "\n",
      "think it ’ s going to be a great fit for what you care about. ” totally missing the point and mis - interpreting the conversation as validation. now fishing for compliments. them : “ cool. i ’ d love to try it when it launches. ” half - hearted compliment plus non - committal stalling tactic. you : “ great — i ’ ll send over one of our beta keys so you can check it out. ” we got a user! them : “ thanks. ” i am literally never going to type that in. the reason this conversation is so very bad is because, if you aren ’ t paying attention, it seems like it went well. if you focus the conversation too quickly on one problem area, you can think you ’ ve validated a “ top ” problem when you haven ’ t. you just led them there. if you ask me what my biggest problem with staying fit is, i ’ ll probably tell you it ’ s the time cost of going to the gym. but then, if you build me a 45\n",
      "\n",
      "chapter two avoiding bad data they say that to bankrupt a fool, give him information. practically everyone i ’ ve seen talk to customers ( including myself ) has been giving themselves bad information. you probably are too. bad data gives us false negatives ( thinking the idea is dead when it ’ s not ) and — more dangerously — false positives ( convincing yourself you ’ re right when you ’ re not ). there are three types of bad data : 1. compliments 2. fluff ( generics, hypotheticals, and the future ) 3. ideas sometimes we invite the bad data ourselves by asking the wrong questions, but even when you try to follow the mom test, conversations still go off track. it could happen because you got excited and started pitching, because you had to talk about your idea to explain the reason for the meeting, or because the conversation is just stuck in hypothetical la - la - land. these things happen. once you start to notice, it ’ s easy to get back on track\n",
      "\n",
      "fix them. 14 good question / bad question let ’ s play a game. are the following questions good or bad? do they pass or fail the mom test? if they fail it, why? and how could we improve them? work your way through the list and then read on for some discussion. “ do you think it ’ s a good idea? ” “ would you buy a product which did x? ” “ how much would you pay for x? ” “ what would your dream product do? ” “ why do you bother? ” “ what are the implications of that? ” “ talk me through the last time that happened. ” “ talk me through your workflow. ” “ what else have you tried? ” “ would you pay x for a product which did y? ” “ how are you dealing with it now? ” “ where does the money come from? ” “ who else should i talk to? ” “ is there anything else i should have asked? ” 15\n",
      "\n",
      "good conversation with a solid negative result. a good ( negative ) conversation : them : “ that ’ s really cool. i love it. ” compliment. you : “ how are you dealing with this stuff at the moment? ” deflect that compliment and get to the real facts. them : “ oh, it ’ s really not that big of a deal for us. we kind of just ignore it. ” the implications of the problem are non - existent so i ’ m not in the market for a solution. you can always be happy with a conversation like the above. you saw through the false compliment and found the facts behind the mirage. if the conversation is going well, i ’ d try to have them talk me through their process anyway so i can try to figure out whether it ’ s an industry wide non - problem or something specific to their particular situation. 27\n",
      "\n",
      "tools and goals. but from the outside, they all look like companies who do sales. even if you narrow it down with a demographic constraint, as these guys did ( sales organisations with 25 - 250 salespeople ), you ’ re still facing unfathomable diversity. they weren ’ t having 20 conversations with their customers. they were having one conversation each with 20 different types of customers. that ’ s why the feedback was so inconsistent. it was as if they were exploring two dozen business ideas simultaneously. 93\n",
      "\n",
      "sitting down to give feedback on wireframes using a trial themselves for a non - trivial period reputation risk commitments might be : intro to peers or team intro to a decision maker ( boss, spouse, lawyer ) giving a public testimonial or case study financial commitments are easier to imagine and include : letter of intent ( non - legal but gentlemanly agreement to purchase ) pre - order deposit sometimes, strong commitments combine multiple currencies, such as someone agreeing to run a paid trial with their whole team, thus risking their time, money, and reputation. just like compliments aren ’ t data when you ’ re trying to learn about a problem, they also aren ’ t progress when you ’ re trying to validate a product. hearing a compliment can still be useful though — it ’ s a warning flag that the person you ’ re talking to is trying to get rid of you. rule of thumb : the more they ’ re giving up, the more seriously you can take their kind words. good meeting / bad meeting\n",
      "\n",
      "accidental approval - seeking is what i call “ the pathos problem. ” it happens when you expose your ego, leading people to feel they ought to protect you by saying nice things. this comes up when you tell someone about an idea you obviously care about ( which is pretty much always, since otherwise you wouldn ’ t be asking ). even if you give folks permission to be honest and ask for criticism, they ’ re still going to pull their punches. 37\n",
      "\n",
      "them every friday. in fact, we didn ’ t even need to build a dashboard at all. and instead of coding up a layout and branding system for the reports, we could have had an intern hand - build them each week. all wasted because i didn ’ t ask the right question. i sure wish i had those 3 months back! when you hear a request, it ’ s your job to understand the motivations which led to it. you do that by digging around the question to find the root cause. why do they bother doing it this way? why do they want the feature? how are they currently coping without the feature? dig. you should dig in the same way around emotional signals to understand where they ’ re coming from. just like feature requests, any strong emotion is worth exploring. is someone angry? dig. embarrassed? dig. overjoyed? dig! i once overheard a founder interviewing someone at a cafe table next to me. the founder mentioned a problem and the guy responded, “ yeah, that ’ s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the worst escenario when asking for feedback?\"\n",
    "results = chroma_collection.query(query_texts=query, n_results=10, include=['documents', 'embeddings'])\n",
    "\n",
    "retrieved_documents = results['documents'][0]\n",
    "\n",
    "for document in results['documents'][0]:\n",
    "    print(document)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 794/794 [00:00<00:00, 2.82MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:12<00:00, 7.52MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 316/316 [00:00<00:00, 1.54MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 1.83MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 602kB/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "-6.768958\n",
      "-10.219069\n",
      "-10.971854\n",
      "-11.008442\n",
      "-11.4253435\n",
      "-11.410198\n",
      "-10.13852\n",
      "-10.082534\n",
      "-10.697642\n",
      "-11.268075\n"
     ]
    }
   ],
   "source": [
    "pairs = [[query, doc] for doc in retrieved_documents]\n",
    "scores = cross_encoder.predict(pairs)\n",
    "\n",
    "print(\"Scores:\")\n",
    "\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Ordering:\n",
      "1\n",
      "8\n",
      "7\n",
      "2\n",
      "9\n",
      "3\n",
      "4\n",
      "10\n",
      "6\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-ranking with Query Expansion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_query = \"What were the most important factors that contributed to increases in revenue?\"\n",
    "generated_queries = [\n",
    "    \"What were the major drivers of revenue growth?\",\n",
    "    \"Were there any new product launches that contributed to the increase in revenue?\",\n",
    "    \"Did any changes in pricing or promotions impact the revenue growth?\",\n",
    "    \"What were the key market trends that facilitated the increase in revenue?\",\n",
    "    \"Did any acquisitions or partnerships contribute to the revenue growth?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [original_query] + generated_queries\n",
    "\n",
    "results = chroma_collection.query(query_texts=queries, n_results=10, include=['documents', 'embeddings'])\n",
    "retrieved_documents = results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deduplicate the retrieved documents\n",
    "unique_documents = set()\n",
    "for documents in retrieved_documents:\n",
    "    for document in documents:\n",
    "        unique_documents.add(document)\n",
    "\n",
    "unique_documents = list(unique_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "for doc in unique_documents:\n",
    "    pairs.append([original_query, doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_encoder.predict(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Scores:\")\n",
    "for score in scores:\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"New Ordering:\")\n",
    "for o in np.argsort(scores)[::-1]:\n",
    "    print(o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
